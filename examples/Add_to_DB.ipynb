{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import networkx as nx\n",
    "import ase\n",
    "import ase.io\n",
    "import time\n",
    "import sqlite3 as sl\n",
    "\n",
    "import ProbAsn.utils as ut\n",
    "import ProbAsn.graph as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = \"../db/\"\n",
    "in_dir = \"../../Data/Additional_dataset/\"\n",
    "ext = \"xyz\"\n",
    "\n",
    "#f = sys.argv[1]\n",
    "f = \"AABHTZ-AFOSOF.xyz\"\n",
    "\n",
    "elems = [\"H\", \"C\", \"N\", \"O\"]\n",
    "all_elems = [\"H\", \"C\", \"N\", \"O\", \"F\", \"S\", \"P\", \"Cl\", \"Na\", \"Ca\", \"K\", \"Mg\"]\n",
    "\n",
    "max_weight = 6\n",
    "thresh = 0.01\n",
    "\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create DB file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lowest_frequency(x):\n",
    "    \n",
    "    z = len(x)\n",
    "    z2 = 1\n",
    "    for i in range(1, len(x)):\n",
    "        if x[i] == x[i-1]:\n",
    "            z2 += 1\n",
    "        else:\n",
    "            z = min(z, z2)\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating graphs for file AABHTZ-AFOSOF.xyz...\n",
      "  Processing structure 10/901, time elapsed 7.22 s, ETA 643.50 s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Generating graphs for file {f}...\")\n",
    "\n",
    "# Load structures\n",
    "structs = ase.io.read(in_dir + f, index=\":\", format=\"extxyz\")\n",
    "n_struct = len(structs)\n",
    "start = time.time()\n",
    "\n",
    "data = {}\n",
    "\n",
    "for e1 in elems:\n",
    "    data[e1] = []\n",
    "    for e2 in elems:\n",
    "        data[f\"{e1}-{e2}\"] = []\n",
    "\n",
    "for istruct, struct in enumerate(structs):\n",
    "\n",
    "    # Print time monitoring\n",
    "    if (istruct + 1) % 10 == 0:\n",
    "        stop = time.time()\n",
    "        dt = stop - start\n",
    "        eta = dt / (istruct + 1) * (n_struct - istruct - 1)\n",
    "        print(f\"  Processing structure {istruct+1}/{n_struct}, time elapsed {dt:.2f} s, ETA {eta:.2f} s\")\n",
    "\n",
    "    # Get structure elements and identifier\n",
    "    sym = struct.get_chemical_symbols()\n",
    "    crystal = struct.info[\"ID\"]\n",
    "\n",
    "    # Get shifts\n",
    "    cs = struct.get_array(\"cs\")\n",
    "\n",
    "    # Get atoms and bonds\n",
    "    atoms, bonds = gr.get_bonds_in_cryst(struct)\n",
    "\n",
    "    # Get zprime\n",
    "    Gs = {}\n",
    "    envs = {}\n",
    "    inds = {}\n",
    "    z = len(atoms)\n",
    "    for e in elems:\n",
    "        if e in sym:\n",
    "            Gs[e], envs[e] = gr.generate_graphs(atoms, bonds, e, max_weight, elems=all_elems)\n",
    "            inds[e] = [i for i, s in enumerate(sym) if s == e]\n",
    "            hs = [gr.generate_hash(G) for G in Gs[e]]\n",
    "            z = min(z, find_lowest_frequency(hs))\n",
    "\n",
    "    for e in Gs:\n",
    "        for env, G, i in zip(envs[e][::z], Gs[e][::z], inds[e][::z]):\n",
    "            \n",
    "            hs = []\n",
    "            for w in range(2, max_weight+1):\n",
    "                cut_G = gr.cut_graph(G, w)\n",
    "                hs.append(gr.generate_hash(cut_G))\n",
    "            \n",
    "            data[e].append((env, crystal, i, cs[i, 0], cs[i, 1], hs[0], hs[1], hs[2], hs[3], hs[4]))\n",
    "            \n",
    "            # 2D graphs\n",
    "            n_nei = len(env.split(\"-\"))\n",
    "            if env == \"\":\n",
    "                n_nei = 0\n",
    "\n",
    "            for j in range(1, n_nei+1):\n",
    "                G2 = G.copy()\n",
    "                enei = G2.nodes[j][\"elem\"]\n",
    "                G2.nodes[j][\"elem\"] = \"Z\"\n",
    "                inei = G2.nodes[j][\"ind\"]\n",
    "                \n",
    "                hs = []\n",
    "                for w in range(2, max_weight+1):\n",
    "                    cut_G = gr.cut_graph(G2, w)\n",
    "                    hs.append(gr.generate_hash(cut_G))\n",
    "                \n",
    "                if enei in elems:\n",
    "                    \n",
    "                    data[f\"{e}-{enei}\"].append((env, crystal, i, cs[i, 0], cs[i, 1], inei, cs[inei, 0], cs[inei, 1], hs[0], hs[1], hs[2], hs[3], hs[4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Updating DB file H...\n",
      "  Updating DB file H-C...\n",
      "  Updating DB file H-N...\n",
      "  Updating DB file H-O...\n",
      "  Updating DB file C...\n",
      "  Updating DB file C-H...\n",
      "  Updating DB file C-C...\n",
      "  Updating DB file C-N...\n",
      "  Updating DB file C-O...\n",
      "  Updating DB file N...\n",
      "  Updating DB file N-H...\n",
      "  Updating DB file N-C...\n",
      "  Updating DB file N-N...\n",
      "  Updating DB file O...\n",
      "  Updating DB file O-H...\n",
      "  Updating DB file O-C...\n"
     ]
    }
   ],
   "source": [
    "# Update DB files\n",
    "\n",
    "for e1 in elems:\n",
    "    \n",
    "    print(f\"  Updating DB file {e1}...\")\n",
    "    \n",
    "    if len(data[e1]) > 0:\n",
    "        \n",
    "        con = sl.connect(f\"{db_dir}ProbAsn_{e1}.db\", timeout=1000)\n",
    "        \n",
    "        n_batch = len(data[e1]) // batch_size + int(len(data[e1]) / batch_size > len(data[e1]) // batch_size)\n",
    "\n",
    "        for ibatch in range(n_batch):\n",
    "\n",
    "            pp = f\"INSERT INTO {e1} (env, crystal, ind, shift, err, G2, G3, G4, G5, G6)\\nVALUES\\n\"\n",
    "\n",
    "            for env, crystal, i, cs, err, h0, h1, h2, h3, h4 in data[e1][ibatch*batch_size:(ibatch+1)*batch_size]:\n",
    "\n",
    "                pp += f\"('{env}', '{crystal}', {i}, {cs}, {err}, '{h0}', '{h1}', '{h2}', '{h3}', '{h4}'),\\n\"\n",
    "\n",
    "            pp = pp[:-2] + \";\"\n",
    "\n",
    "            with con:\n",
    "                con.execute(pp)\n",
    "            \n",
    "        con.commit()\n",
    "        con.close()\n",
    "    \n",
    "    for e2 in elems:\n",
    "        if len(data[f\"{e1}-{e2}\"]) > 0:\n",
    "            \n",
    "            print(f\"  Updating DB file {e1}-{e2}...\")\n",
    "\n",
    "\n",
    "            con = sl.connect(f\"{db_dir}ProbAsn_{e1}-{e2}.db\", timeout=1000)\n",
    "\n",
    "            n_batch = len(data[f\"{e1}-{e2}\"]) // batch_size + int(len(data[f\"{e1}-{e2}\"]) / batch_size > len(data[f\"{e1}-{e2}\"]) // batch_size)\n",
    "\n",
    "            for ibatch in range(n_batch):\n",
    "\n",
    "                pp = f\"INSERT INTO {e1}_{e2} (env, crystal, ind, shift, err, nei_ind, nei_shift, nei_err, G2, G3, G4, G5, G6)\\nVALUES\\n\"\n",
    "\n",
    "                for env, crystal, i, cs, err, inei, csnei, errnei, h0, h1, h2, h3, h4 in data[f\"{e1}-{e2}\"][ibatch*batch_size:(ibatch+1)*batch_size]:\n",
    "\n",
    "                    pp += f\"('{env}', '{crystal}', {i}, {cs}, {err}, {inei}, {csnei}, {errnei}, '{h0}', '{h1}', '{h2}', '{h3}', '{h4}'),\\n\"\n",
    "\n",
    "                pp = pp[:-2] + \";\"\n",
    "\n",
    "                with con:\n",
    "                    con.execute(pp)\n",
    "\n",
    "            con.commit()\n",
    "            con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProbAsn",
   "language": "python",
   "name": "probasn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
